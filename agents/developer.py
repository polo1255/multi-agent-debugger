# file: agents/developer.py

import os
import re
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á State
from graph.state import AgentState

load_dotenv()

# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ API Key ‡πÑ‡∏´‡∏ô‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ö‡πâ‡∏≤‡∏á (DeepSeek ‡∏´‡∏£‡∏∑‡∏≠ OpenAI)
if os.getenv("DEEPSEEK_API_KEY"):
    llm = ChatOpenAI(
        model="deepseek-coder", 
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com",
        temperature=0.2
    )
else:
    # Fallback ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ DeepSeek
    llm = ChatOpenAI(
        model="gpt-3.5-turbo", 
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0.2
    )

def extract_code_content(text):
    """
    Upgraded function version: Extract code in any language.
    Whether it's JavaScript, Python, or Java.
    """
    # 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Pattern ```python ... ```
    pattern = r"```(?:\w+)?\s*\n?(.*?)```"
    match = re.search(pattern, text, re.DOTALL)
    
    if match:
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
        return match.group(1).strip()
    
    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ Markdown ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏´‡∏°
    # ‡∏ñ‡πâ‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà def ‡∏´‡∏£‡∏∑‡∏≠ import ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏û‡∏π‡∏î
    lines = text.strip().split('\n')
    clean_lines = []
    started = False
    code_starters = ('def ', 'class ', 'import ', 'from ', '@', 'function ', 'const ', 'let ', 'var ', 'package ')
    for line in lines:
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠ def, class, import ‡∏´‡∏£‡∏∑‡∏≠ from
        if line.strip().startswith(('def ', 'class ', 'import ', 'from ', '@')):
            started = True
        if started:
            clean_lines.append(line)
            
    if clean_lines:
        return '\n'.join(clean_lines)

    # 3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏•‡∏¢ ‡∏Å‡πá‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏î‡∏∑‡πâ‡∏≠‡πÜ (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏±‡∏ô‡∏™‡πà‡∏á‡∏°‡∏≤‡πÅ‡∏ï‡πà‡πÇ‡∏Ñ‡πâ‡∏î‡∏•‡πâ‡∏ß‡∏ô)
    return text.strip()

def developer_node(state: AgentState):
    """
    Developer Agent: ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Error ‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏≠‡∏î‡∏µ‡∏ï (RAG)
    """
    current_iteration = state.get('iteration_count', 0) + 1

    print(f"--- DEVELOPER AGENT IS WORKING (Round: {current_iteration}) ---")

    current_code = state['code_base']
    error = state['error_context']
    feedback = state.get('reflection_logs', [])
    
    # üî• ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Knowledge Context ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å Server
    knowledge = state.get('knowledge_context', "")
    
    # 1. ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á System Prompt ‡πÉ‡∏´‡πâ AI ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÉ‡∏ä‡πâ Reference
    system_prompt = """You are a Universal Software Engineer expert.
    Your task is to fix bugs while OPTIMIZING performance.
    
    GUIDELINES:
        1. Identify the programming language.
        2. Analyze the bug and the Time/Space Complexity of the original code.
        3. Fix the bug using the MOST EFFICIENT algorithm (e.g., prefer O(n) over O(n^2)).
        4. If using loops, ensure they are necessary. Use hash maps (dict) for lookups instead of lists where possible.
        5. Return ONLY the fixed code in markdown code blocks.
    """
    
    # 2. ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á User Content ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏™‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å ChromaDB ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ
    user_content = f"### BROKEN CODE:\n{current_code}\n\n### ERROR CONTEXT:\n{error}"
    
    # üî• ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡∏â‡∏µ‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Prompt ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
    if knowledge:
        user_content += f"\n\n### PAST KNOWLEDGE (Use as reference):\n{knowledge}"
    
    if feedback:
        user_content += f"\n\n### FEEDBACK FROM REVIEWER:\n{feedback[-1]}"

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_content)
    ]
    
    response = llm.invoke(messages)
    raw_content = response.content
    
    fixed_code = extract_code_content(raw_content)
            
    print("--- DEVELOPER AGENT FINISHED ---")

    return {
        "code_base": fixed_code,
        "iteration_count": current_iteration
    }